{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"./processed_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features():\n",
    "    \"\"\"\n",
    "    Load pre-processed feature matrices.\n",
    "    \"\"\"\n",
    "    Xs = np.load(INPUT_DIR + 'X.npz')\n",
    "    ys = np.load(INPUT_DIR + 'y.npz')\n",
    "    X_train, X_test = Xs['train'], Xs['test']\n",
    "    y_train, y_test = ys['train'], ys['test']\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Title:       train.py\n",
    "Description: Collection of functions to train the model.\n",
    "Author:      Kunyu He, CAPP'20\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "INPUT_DIR = \"./processed_data/\"\n",
    "MODEL_NAMES = [\"KNN\", \"Decision Tree\", \"Random Forest\"]\n",
    "METRICS = [\"ROC AUC\", \"Accuracy\"]\n",
    "GRID_SEARCH_PARAMS = {\"KNN\": {'n_neighbors': list(range(1, 41, 2)),\n",
    "                              'p': list(range(1, 4))\n",
    "                              },\n",
    "                      \"Decision Tree\": {'criterion': [\"entropy\", \"gini\"],\n",
    "                            'min_samples_split': list(np.arange(0.01, 0.11, 0.01)),\n",
    "                            'max_depth': list(range(1, 11)),\n",
    "                            'max_features': list(range(4, 17, 2))\n",
    "                            },\n",
    "                      \"Random Forest\": {'n_estimators': list(range(100, 500, 100)),\n",
    "                            'min_samples_split': list(np.arange(0.01, 0.06, 0.01)),\n",
    "                            'max_depth': list(range(4, 11)),\n",
    "                            'max_features': list(range(4, 17, 2))\n",
    "                            }\n",
    "                      }\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------#\n",
    "def load_features():\n",
    "    \"\"\"\n",
    "    Load pre-processed feature matrices.\n",
    "    \"\"\"\n",
    "    Xs = np.load(INPUT_DIR + 'X.npz')\n",
    "    ys = np.load(INPUT_DIR + 'y.npz')\n",
    "    X_train, X_test = Xs['train'], Xs['test']\n",
    "    y_train, y_test = ys['train'], ys['test']\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def evaluate(classifier, X_test, y_test, metric=\"ROC AUC\"):\n",
    "    \"\"\"\n",
    "    Evaluate the fitted classifier on the test set and calculate the\n",
    "    evaluation metrics.\n",
    "    \"\"\"\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    if metric == \"Accuracy\":\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "\n",
    "    fp_rate, tp_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    return auc(fp_rate, tp_rate)\n",
    "\n",
    "\n",
    "def build_benchmark(X_train, y_train, X_test, y_test, metric=\"ROC AUC\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    benchmark_classifier = DecisionTreeClassifier(random_state=123)\n",
    "    benchmark_classifier.fit(X_train, y_train)\n",
    "\n",
    "    return evaluate(benchmark_classifier, X_test, y_test, metric=metric)\n",
    "\n",
    "\n",
    "def tune(model, parameters, X_train, y_train, metric=\"ROC AUC\", n_folds=5,\n",
    "         default_args={}):\n",
    "    \"\"\"\n",
    "    Use grid search and cross validation to find the best set of hyper-\n",
    "    parameters.\n",
    "    \"\"\"\n",
    "    classifier = model(**default_args)\n",
    "    if metric == \"ROC AUC\":\n",
    "        score = \"roc_auc\"\n",
    "    else:\n",
    "        score = \"accuracy\"\n",
    "\n",
    "    grid = GridSearchCV(classifier, param_grid=parameters, scoring=score,\n",
    "                        n_jobs=-1, cv=n_folds, iid=True, verbose=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    return model(**grid.best_params_, **default_args), grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_index, metric_index, folds = 3, 1, 3\n",
    "metric_name = [\"ROC AUC\", \"Accuracy\"][metric_index - 1]\n",
    "model_name = [\"KNN\", \"Decision Tree\", \"Random Forest\"][model_index - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC of the benchmark default decision tree model is 0.659.\n"
     ]
    }
   ],
   "source": [
    "benchmark_score = build_benchmark(X_train, y_train, X_test, y_test,\n",
    "                                  metric=metric_name)\n",
    "print(\"{} of the benchmark default decision tree model is {}.\".\\\n",
    "      format(metric_name, round(benchmark_score, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = GRID_SEARCH_PARAMS[model_name]\n",
    "args = [parameters, X_train, y_train]\n",
    "op_args = {'metric': metric_name, 'n_folds': folds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 980 candidates, totalling 2940 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 37.9min\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed: 48.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed: 58.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 71.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 86.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2162 tasks      | elapsed: 105.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed: 214.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2940 out of 2940 | elapsed: 233.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the best set of parameters for Random Forest Classifier: {'max_depth': 10, 'max_features': 4, 'min_samples_split': 0.01, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "if model_name == \"KNN\":\n",
    "    best_classifier, grid = tune(KNeighborsClassifier, *args, **op_args,\n",
    "                                 default_args={'n_jobs': -1})\n",
    "elif model_name == \"Decision Tree\":\n",
    "    best_classifier, grid = tune(DecisionTreeClassifier, *args, **op_args,\n",
    "                                 default_args={'random_state': 123})\n",
    "else:\n",
    "    best_classifier, grid = tune(RandomForestClassifier, *args, **op_args,\n",
    "                                 default_args={'random_state': 123,\n",
    "                                               'oob_score': True})\n",
    "print(\"Found the best set of parameters for {} Classifier: {}\".\\\n",
    "      format(model_name, grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC of the tuned Random Forest is 0.683, 0.024 higher than the benchmark.\n"
     ]
    }
   ],
   "source": [
    "best_classifier.fit(X_train, y_train)\n",
    "best_score = evaluate(best_classifier, X_test, y_test, metric=metric_name)\n",
    "diff = round(best_score - benchmark_score, 3)\n",
    "print(\"{} of the tuned {} is {}, {} {} than the benchmark.\".\\\n",
    "      format(metric_name, model_name, round(best_score, 3), diff,\n",
    "             ['higher', 'lower'][int(diff <= 0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8728400433573856"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': [1,\n",
       "  3,\n",
       "  5,\n",
       "  7,\n",
       "  9,\n",
       "  11,\n",
       "  13,\n",
       "  15,\n",
       "  17,\n",
       "  19,\n",
       "  21,\n",
       "  23,\n",
       "  25,\n",
       "  27,\n",
       "  29,\n",
       "  31,\n",
       "  33,\n",
       "  35,\n",
       "  37,\n",
       "  39],\n",
       " 'p': [1, 2, 3]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'n_neighbors': list(range(1, 41, 2)), 'p': list(range(1, 4))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30762, 16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1a17564d2b76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m {'criterion': [\"entropy\", \"gini\"],\n\u001b[1;32m----> 2\u001b[1;33m                            \u001b[1;34m'min_samples_split'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m                            'max_features': list(range(4, 17, 2))}\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    " {'criterion': [\"entropy\", \"gini\"],\n",
    "                            'min_samples_split': list(range(0.01, 0.11, 0.01)),\n",
    "                            'max_features': list(range(4, 17, 2))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-bd9977b1d196>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.02\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "list(range(0.01, 0.11, 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01,\n",
       " 0.03,\n",
       " 0.049999999999999996,\n",
       " 0.06999999999999999,\n",
       " 0.08999999999999998,\n",
       " 0.10999999999999997]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.arange(0.01, 0.13, 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
